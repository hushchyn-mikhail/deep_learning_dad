{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s347J0P3qaEY"
      },
      "source": [
        "# Семинар 2\n",
        "\n",
        "Casting, autograd и первая нейросеть!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIEz08PIqaEe"
      },
      "source": [
        "## Casting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omgB0qixqaEe"
      },
      "outputs": [],
      "source": [
        "# Helper to get what kind of tensor types\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bll4HIzRqaEe",
        "outputId": "d5a97fd0-3cf4-40c3-83c2-9165fddd896d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2., 5., 3., 7.],\n",
              "         [4., 2., 1., 9.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(m, dtype=torch.bfloat16, device='cuda:2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L66nFeGTvWQW",
        "outputId": "3810ae26-156c-4428-8c47-de7f890abf76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-ad73a2903e09>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t = torch.tensor(m, dtype=torch.bfloat16, device='cuda')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.to(torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiECHMm-vehv",
        "outputId": "348fd6c9-b123-44ff-e8e6-3a867dcb7fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2., 5., 3., 7.],\n",
              "         [4., 2., 1., 9.]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lq83nVvVv9CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6cn-FX_qaEe"
      },
      "outputs": [],
      "source": [
        "# This is basically a 64 bit float tensor\n",
        "m_double = m.double()\n",
        "m_double"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzO1w_htqaEe"
      },
      "outputs": [],
      "source": [
        "# This creates a tensor of type int8\n",
        "m_byte = m.byte()\n",
        "m_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmuwWwEcqaEf",
        "outputId": "60e72b92-0543-41cc-c14a-edffcb4d2d07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2., 5., 3., 7.],\n",
              "         [4., 2., 1., 9.]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "m.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv_kOTxkqaEf",
        "outputId": "aeb895cc-86c7-4f13-9760-813aaf7c0efd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 5., 3., 7.],\n",
              "       [4., 2., 1., 9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Converts tensor to numpy array\n",
        "m_np = m.numpy()\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE9Jd9GtqaEf",
        "outputId": "71ea9a24-de3f-493e-c4c4-ffc4039d1cea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.,  5.,  3.,  7.],\n",
              "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# In-place fill of column 0 and row 0 with value -1\n",
        "m_np[0, 0] = -1\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-8tEGTNqaEf",
        "outputId": "7606d0c4-81fd-4bbf-d4b1-e5deffe39c6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  5.,  3.,  7.],\n",
              "        [ 4.,  2.,  1.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdKSQgKDqaEf",
        "outputId": "6cb04215-dfcf-45b8-d04d-4184bee1f5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4] tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of integers ranging from 0 to 4\n",
        "import numpy as np\n",
        "n_np = np.arange(5)\n",
        "n = torch.from_numpy(n_np)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATGDBL35qaEf",
        "outputId": "b6c77991-cc13-4dcc-c55f-6a9126644e5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 4, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# In-place multiplication of all elements by 2 for tensor n\n",
        "# Because n is essentially n_np, not a clone, this affects n_np\n",
        "n.mul_(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.Tensor(2, 2)"
      ],
      "metadata": {
        "id": "TaXt5S-Zw6Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "id": "LWaJLO2tw_5V",
        "outputId": "dc6d1ce5-37c6-4906-89ae-9cefdf18b059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 0.0000e+00],\n",
              "        [1.1351e-43, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[None, :, :]"
      ],
      "metadata": {
        "id": "vNc2FPYexAdd",
        "outputId": "930bf47c-7a7d-41cb-bc25-5561d763b8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000e+00, 0.0000e+00],\n",
              "         [1.1351e-43, 0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BERLnqGSqaEf"
      },
      "source": [
        "## More fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbxitlMkqaEf",
        "outputId": "8b586f81-4110-455f-a051-fb15addd6122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4]) tensor([[5., 6., 7., 8.]])\n"
          ]
        }
      ],
      "source": [
        "# Creates two tensors of size 1x4\n",
        "a = torch.Tensor([[1, 2, 3, 4]])\n",
        "b = torch.Tensor([[5, 6, 7, 8]])\n",
        "print(a.size(), b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYzJIN7MqaEf",
        "outputId": "7f9c0c18-fb5e-49c3-cfeb-b5b220feba7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4.],\n",
              "        [5., 6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Concatenate on axis 0, so you get 2x4\n",
        "torch.cat((a, b), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnX69pdeqaEf",
        "outputId": "c48e91d5-b4f3-4b9f-96fd-da500999f937"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Concatenate on axis 1, so you get 1x8\n",
        "torch.cat((a, b), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WV1p69BqaEf"
      },
      "source": [
        "### [Автоматическое дифференцирование](https://pytorch.org/docs/stable/notes/autograd.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Hy3OvTqaEf",
        "outputId": "023e2e73-dc5e-4563-daf3-9c269b458574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0669, 0.1527, 0.4376, 0.7911, 0.3413])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.rand(5)\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([2, 2, 3], dtype=torch.bfloat16, device='cuda', requires_grad=True)"
      ],
      "metadata": {
        "id": "CGGsT6sKzvck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "t.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ci-7na70Dx0",
        "outputId": "36f9910c-707d-4043-dfa8-c26a51ac818a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 3.], device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo9OjVhaqaEf",
        "outputId": "f1ca7508-d7f9-4c0c-e29b-0afbd683d955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5917, 0.0359, 0.2763, 0.8524, 0.4772],\n",
              "        [0.6546, 0.4645, 0.2239, 0.6609, 0.6132],\n",
              "        [0.4657, 0.4555, 0.4197, 0.8770, 0.0949]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "w = torch.rand(3, 5, requires_grad=True)\n",
        "\n",
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LRKTfEUqaEf",
        "outputId": "76e6de49-71d4-40af-c96e-598c544995c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URo6EitoqaEf",
        "outputId": "5a0c95d0-1c07-4a50-9a33-54a8ec984112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.3021e-30, 0.0000e+00, 5.2559e-30])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "first_z = torch.empty(3)\n",
        "\n",
        "first_z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ChHQCvYqaEf",
        "outputId": "dcd0193d-cc62-445e-d582-f07a5580c8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0032, 0.9448, 1.0106], grad_fn=<CopySlices>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    first_z[i] = torch.sum(w[i] * x)\n",
        "\n",
        "first_z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BpBcmoGqaEf",
        "outputId": "efef133d-6780-4846-a7a0-9fa6fc66da7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0032, 0.9448, 1.0106], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "z = torch.matmul(x, w.t())\n",
        "\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zvJfOlvqaEf",
        "outputId": "e85545c7-2b0a-4354-a16c-ec1b5d7ea098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4768, 0.8453, 0.3889], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "v = torch.rand(3, requires_grad=True)\n",
        "\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVKEjO_GqaEf",
        "outputId": "aa8820dc-86c5-4c41-f611-c645132a107c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(v.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn1icI56qaEf",
        "outputId": "bfa05c9e-5be6-451f-ae63-74a1a474e9ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6700, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y = torch.sum(z * v)\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sPwqIpxqaEf",
        "outputId": "075b43a7-83b6-48cb-9079-392f18b1d3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.669968605041504"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QipdKCVDqaEg",
        "outputId": "7b46948c-8fed-4976-b9d5-53e1bec97f67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10892072319984436"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "loss = torch.mean((y - 2) ** 2)\n",
        "\n",
        "loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujDzh4hQqaEg",
        "outputId": "2c77cb56-95ab-48b6-c57c-8457f6fd5529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad=None\n",
            "\n",
            "w.grad=None\n",
            "\n",
            "z.grad=None\n",
            "\n",
            "v.grad=None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-b1828bd1c118>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(f'{z.grad=}\\n')\n"
          ]
        }
      ],
      "source": [
        "print(f'{x.grad=}\\n')\n",
        "print(f'{w.grad=}\\n')\n",
        "print(f'{z.grad=}\\n')\n",
        "print(f'{v.grad=}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdXwb8xNqaEg"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y3Iyye1qaEg",
        "outputId": "938f9794-a09f-4e63-e524-324ef42371a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad=None\n",
            "\n",
            "w.grad=tensor([[-0.0211, -0.0481, -0.1377, -0.2489, -0.1074],\n",
            "        [-0.0373, -0.0852, -0.2442, -0.4414, -0.1904],\n",
            "        [-0.0172, -0.0392, -0.1123, -0.2031, -0.0876]])\n",
            "\n",
            "z.grad=None\n",
            "\n",
            "v.grad=tensor([-0.6621, -0.6237, -0.6670])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-b1828bd1c118>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(f'{z.grad=}\\n')\n"
          ]
        }
      ],
      "source": [
        "print(f'{x.grad=}\\n')\n",
        "print(f'{w.grad=}\\n')\n",
        "print(f'{z.grad=}\\n')\n",
        "print(f'{v.grad=}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus part"
      ],
      "metadata": {
        "id": "SQtjW80ro1hk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBY2T4rqqaEg"
      },
      "source": [
        "## Полносвязные слои и функции активации в `PyTorch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUd8bYGiqaEg"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U1xcI2GqaEg"
      },
      "source": [
        "### Полносвязный слой\n",
        "\n",
        ">$y_j = \\sum\\limits_{i=1}^{n}x_iw_{ji} + b_j$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Linear?"
      ],
      "metadata": {
        "id": "D_1WW4K33Z27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpWF9a_n32qq",
        "outputId": "6c7b215f-3249-45b8-d766-f427a16f8df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4548e-33, 0.0000e+00, 0.0000e+00, 2.3510e-38, 1.0489e-36])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xIqfcgDlp5QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NRpc680LqJnN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmR_SRGKqaEg",
        "outputId": "99c502b0-2023-429d-8d04-dc7e7a8aff98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5.0320e+24,  2.3017e+24, -3.2802e+24], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "layer = nn.Linear(in_features=5, out_features=3)\n",
        "x = torch.Tensor((5))\n",
        "layer(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67pHbQMUqaEg",
        "outputId": "f12c7fff-0eb4-48da-c2f9-a92345c3edfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.3524,  0.0397, -0.3125, -0.2296,  0.2872],\n",
              "        [-0.1612,  0.2295,  0.3860,  0.1993, -0.0994],\n",
              "        [ 0.2297, -0.1026,  0.3758,  0.3847,  0.2187]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "layer.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6XFk2McqaEg",
        "outputId": "537c6a3f-a792-45d1-c54b-a2e048aeec13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(layer.weight.shape)\n",
        "display(layer.bias.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghUIGwjOqaEg"
      },
      "outputs": [],
      "source": [
        "layer = nn.Linear(in_features=5, out_features=3, bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBarp40fqaEg"
      },
      "outputs": [],
      "source": [
        "layer.weight.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEK-YHutqaEg"
      },
      "source": [
        "### Функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ankFdtiuqaEg"
      },
      "source": [
        "> Сигмоида $f(x) = \\dfrac{1}{1 + e^{-x}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R10_-u8oqaEg"
      },
      "outputs": [],
      "source": [
        "activation = nn.Sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h26r2qMlqaEg",
        "outputId": "19394a20-6726-415c-999b-00b44a80f812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9211, -0.6740,  0.8187, -0.3292,  1.1349])\n",
            "tensor([0.7153, 0.3376, 0.6940, 0.4184, 0.7567])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(5)\n",
        "\n",
        "print(x)\n",
        "\n",
        "print(activation(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5TVVBUdqaEg"
      },
      "source": [
        "> ReLU $f(x) = \\max(0, x)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLujNjt-qaEg"
      },
      "outputs": [],
      "source": [
        "activation = nn.ReLU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOVtQgzeqaEg",
        "outputId": "d44d8ac6-3ee0-4970-967c-509880a58aef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1228, -0.3128,  0.7083,  0.9356,  0.6187])\n",
            "tensor([0.1228, 0.0000, 0.7083, 0.9356, 0.6187])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(5)\n",
        "\n",
        "print(x)\n",
        "\n",
        "print(activation(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGdkIrglqaEg"
      },
      "source": [
        "## Линейная регрессия"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LyND87T_GFz",
        "outputId": "cd5e1a48-f7aa-40c4-edcb-797258ea65d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDzeATY1qaEg",
        "outputId": "cfd7d5ac-8276-4bcf-9e9b-2026fb21a0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[2.],\n",
              "        [4.],\n",
              "        [6.]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 19.167205810546875\n",
            "epoch 1, loss 15.756294250488281\n",
            "epoch 2, loss 12.952374458312988\n",
            "epoch 3, loss 10.647427558898926\n",
            "epoch 4, loss 8.752659797668457\n",
            "epoch 5, loss 7.195074558258057\n",
            "epoch 6, loss 5.914671421051025\n",
            "epoch 7, loss 4.862123012542725\n",
            "epoch 8, loss 3.9968807697296143\n",
            "epoch 9, loss 3.285613775253296\n",
            "epoch 10, loss 2.7009201049804688\n",
            "epoch 11, loss 2.220276117324829\n",
            "epoch 12, loss 1.8251657485961914\n",
            "epoch 13, loss 1.500367283821106\n",
            "epoch 14, loss 1.2333687543869019\n",
            "epoch 15, loss 1.0138837099075317\n",
            "epoch 16, loss 0.8334571719169617\n",
            "epoch 17, loss 0.6851387023925781\n",
            "epoch 18, loss 0.5632143020629883\n",
            "epoch 19, loss 0.4629875123500824\n",
            "epoch 20, loss 0.38059648871421814\n",
            "epoch 21, loss 0.312867134809494\n",
            "epoch 22, loss 0.2571905255317688\n",
            "epoch 23, loss 0.21142220497131348\n",
            "epoch 24, loss 0.1737985759973526\n",
            "epoch 25, loss 0.14287002384662628\n",
            "epoch 26, loss 0.1174454316496849\n",
            "epoch 27, loss 0.09654537588357925\n",
            "epoch 28, loss 0.07936457544565201\n",
            "epoch 29, loss 0.06524118036031723\n",
            "epoch 30, loss 0.05363111570477486\n",
            "epoch 31, loss 0.04408712312579155\n",
            "epoch 32, loss 0.036241594702005386\n",
            "epoch 33, loss 0.029792243614792824\n",
            "epoch 34, loss 0.024490520358085632\n",
            "epoch 35, loss 0.020132340490818024\n",
            "epoch 36, loss 0.01654963381588459\n",
            "epoch 37, loss 0.013604513369500637\n",
            "epoch 38, loss 0.011183511465787888\n",
            "epoch 39, loss 0.009193327277898788\n",
            "epoch 40, loss 0.007557359989732504\n",
            "epoch 41, loss 0.006212498527020216\n",
            "epoch 42, loss 0.005106950644403696\n",
            "epoch 43, loss 0.004198149312287569\n",
            "epoch 44, loss 0.0034510695841163397\n",
            "epoch 45, loss 0.0028369438368827105\n",
            "epoch 46, loss 0.0023320955224335194\n",
            "epoch 47, loss 0.0019170843297615647\n",
            "epoch 48, loss 0.001575937494635582\n",
            "epoch 49, loss 0.001295470050536096\n",
            "epoch 50, loss 0.0010649412870407104\n",
            "epoch 51, loss 0.0008754239534027874\n",
            "epoch 52, loss 0.000719645933713764\n",
            "epoch 53, loss 0.0005915786605328321\n",
            "epoch 54, loss 0.0004863080976065248\n",
            "epoch 55, loss 0.00039977129199542105\n",
            "epoch 56, loss 0.0003286272694822401\n",
            "epoch 57, loss 0.00027014382067136467\n",
            "epoch 58, loss 0.00022206785797607154\n",
            "epoch 59, loss 0.00018255342729389668\n",
            "epoch 60, loss 0.00015006483590696007\n",
            "epoch 61, loss 0.00012335878273006529\n",
            "epoch 62, loss 0.0001014073277474381\n",
            "epoch 63, loss 8.335793972946703e-05\n",
            "epoch 64, loss 6.852667866041884e-05\n",
            "epoch 65, loss 5.633282125927508e-05\n",
            "epoch 66, loss 4.63088508695364e-05\n",
            "epoch 67, loss 3.806769382208586e-05\n",
            "epoch 68, loss 3.1293780921259895e-05\n",
            "epoch 69, loss 2.5726638341438957e-05\n",
            "epoch 70, loss 2.115015195158776e-05\n",
            "epoch 71, loss 1.7384525563102216e-05\n",
            "epoch 72, loss 1.429154144716449e-05\n",
            "epoch 73, loss 1.174776116386056e-05\n",
            "epoch 74, loss 9.658230737841222e-06\n",
            "epoch 75, loss 7.939375791465864e-06\n",
            "epoch 76, loss 6.527646746690152e-06\n",
            "epoch 77, loss 5.365480319596827e-06\n",
            "epoch 78, loss 4.410137080412824e-06\n",
            "epoch 79, loss 3.6260705655877246e-06\n",
            "epoch 80, loss 2.980540330099757e-06\n",
            "epoch 81, loss 2.449554585837177e-06\n",
            "epoch 82, loss 2.0139748357905773e-06\n",
            "epoch 83, loss 1.6560861695325002e-06\n",
            "epoch 84, loss 1.3613631608677679e-06\n",
            "epoch 85, loss 1.119148805628356e-06\n",
            "epoch 86, loss 9.20300180951017e-07\n",
            "epoch 87, loss 7.563872372884362e-07\n",
            "epoch 88, loss 6.216068300091138e-07\n",
            "epoch 89, loss 5.1105297416143e-07\n",
            "epoch 90, loss 4.2021096646749356e-07\n",
            "epoch 91, loss 3.454787531609327e-07\n",
            "epoch 92, loss 2.8394740070325497e-07\n",
            "epoch 93, loss 2.3339559618307248e-07\n",
            "epoch 94, loss 1.9193095113223535e-07\n",
            "epoch 95, loss 1.575993024971467e-07\n",
            "epoch 96, loss 1.2953138650573237e-07\n",
            "epoch 97, loss 1.066265795657273e-07\n",
            "epoch 98, loss 8.763930736677139e-08\n",
            "epoch 99, loss 7.211359331904532e-08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1.9999]], requires_grad=True)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict (after training) 4 7.99954891204834\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
        "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))\n",
        "\n",
        "display(x_data)\n",
        "display(y_data)\n",
        "\n",
        "class LinearRegressionModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "\n",
        "        self.linear = torch.nn.Linear(1, 1, bias=False)  # One in and one out\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = self.linear(x)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# our model\n",
        "our_model = LinearRegressionModel()\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(our_model.parameters(), lr = 0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    # Forward pass: Compute predicted y by passing\n",
        "    # x to the model\n",
        "    pred_y = our_model(x_data)\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_data, pred_y)\n",
        "    # Zero gradients, perform a backward pass,\n",
        "    # and update the weights.\n",
        "    # display(our_model.linear.weight.grad)\n",
        "    optimizer.zero_grad()\n",
        "    # display(our_model.linear.weight.grad)\n",
        "    loss.backward()\n",
        "    # display(our_model.linear.weight.grad)\n",
        "    # display(our_model.linear.weight)\n",
        "    optimizer.step()\n",
        "    # display(our_model.linear.weight)\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "display(our_model.linear.weight)\n",
        "new_var = Variable(torch.Tensor([[4.0]]))\n",
        "pred_y = our_model(new_var)\n",
        "print(\"predict (after training)\", 4, our_model(new_var).item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9v0h4D_qaEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7c3de7-8cd2-4ef4-81a2-2d57e1778d76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.5274], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "our_model.linear.bias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1.7680*4 + our_model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zTCNmrjwLqZ",
        "outputId": "ad6801a7-9a7a-4030-e8df-5a2f44d2c1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.5994], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.Linear??"
      ],
      "metadata": {
        "id": "AM68IFahwUsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Lwulu6Qwp0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}