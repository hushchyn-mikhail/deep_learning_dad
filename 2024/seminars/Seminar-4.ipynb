{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbadb2a2",
   "metadata": {},
   "source": [
    "## Регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb2cd8",
   "metadata": {},
   "source": [
    "### Давайте теперь рассмотрим различные методы прунинга и регуляризации моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578437b",
   "metadata": {},
   "source": [
    "##### Подключим библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc7938da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a92bb",
   "metadata": {},
   "source": [
    "###### Прочтем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf5f76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"sonar.csv\", header=None)\n",
    "X = data.iloc[:, 0:60]\n",
    "y = data.iloc[:, 60]\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e44d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target from string to integer\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "# Convert to 2D PyTorch tensors\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b49c5",
   "metadata": {},
   "source": [
    "Базовая модель, без регуляризаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1534ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 30)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdb48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val,\n",
    "                n_epochs=300, batch_size=16):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for start in batch_start:\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    y_pred = model(X_val)\n",
    "    acc = (y_pred.round() == y_val).float().mean()\n",
    "    acc = float(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc6281e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.81\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.86\n",
      "Accuracy: 0.80\n",
      "Accuracy: 0.80\n",
      "Overal for baseline model: 82.67% (+/- 6.87%)\n"
     ]
    }
   ],
   "source": [
    "# run 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model, train, and get accuracy\n",
    "    model = BaseModel()\n",
    "    acc = model_train(model, X[train], y[train], X[test], y[test])\n",
    "    print(\"Accuracy: %.2f\" % acc)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "mean = np.mean(accuracies)\n",
    "std = np.std(accuracies)\n",
    "print(\"Overal for baseline model: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ffe73",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "А теперь добавим дропаут в начале"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a13e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.2) ## Adding a dropout layer\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 30)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e523c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Accuracy: 0.86\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.67\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.86\n",
      "Accuracy: 0.76\n",
      "Accuracy: 0.85\n",
      "Accuracy: 0.80\n",
      "Overall for input-dropout: 79.83% (+/- 7.56%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model, train, and get accuracy\n",
    "    model = SonarModel()\n",
    "    acc = model_train(model, X[train], y[train], X[test], y[test])\n",
    "    print(\"Accuracy: %.2f\" % acc)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "# evaluate the model\n",
    "mean = np.mean(accuracies)\n",
    "std = np.std(accuracies)\n",
    "print(\"Overall for input-dropout: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209c51d",
   "metadata": {},
   "source": [
    "А теперь применим дропаут к внутреннему слою"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1975edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(60, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.layer2 = nn.Linear(60, 30)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.output = nn.Linear(30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe65c97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.86\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.86\n",
      "Accuracy: 0.71\n",
      "Accuracy: 0.90\n",
      "Accuracy: 0.81\n",
      "Accuracy: 0.85\n",
      "Accuracy: 0.85\n",
      "OVeral for hidden-dropout: 82.71% (+/- 6.40%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "accuracies = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model, train, and get accuracy\n",
    "    model = SonarModel()\n",
    "    acc = model_train(model, X[train], y[train], X[test], y[test])\n",
    "    print(\"Accuracy: %.2f\" % acc)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "mean = np.mean(accuracies)\n",
    "std = np.std(accuracies)\n",
    "print(\"OVeral for hidden-dropout: %.2f%% (+/- %.2f%%)\" % (mean*100, std*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5668c13",
   "metadata": {},
   "source": [
    "### L1, L2 and elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe5f73",
   "metadata": {},
   "source": [
    "##### L1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd9c6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(28 * 28 * 1, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)\n",
    "  \n",
    "    def compute_l1_loss(self, w):\n",
    "        return torch.abs(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f01164ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "  \n",
    "# Prepare CIFAR-10 dataset\n",
    "dataset = MNIST(os.getcwd(), download=True, train=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)\n",
    "\n",
    "# Initialize the MLP\n",
    "mlp = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "losses_l1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10e17a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 65.37165 (of which 63.03826 L1 loss)\n",
      "Loss after mini-batch  1000: 13.89388 (of which 11.59544 L1 loss)\n",
      "Loss after mini-batch  1500: 3.68279 (of which 1.37783 L1 loss)\n",
      "Loss after mini-batch  2000: 2.93884 (of which 0.63626 L1 loss)\n",
      "Loss after mini-batch  2500: 2.93945 (of which 0.63686 L1 loss)\n",
      "Loss after mini-batch  3000: 2.93972 (of which 0.63713 L1 loss)\n",
      "Loss after mini-batch  3500: 2.93790 (of which 0.63531 L1 loss)\n",
      "Loss after mini-batch  4000: 2.94024 (of which 0.63766 L1 loss)\n",
      "Loss after mini-batch  4500: 2.94047 (of which 0.63787 L1 loss)\n",
      "Loss after mini-batch  5000: 2.93992 (of which 0.63733 L1 loss)\n",
      "Loss after mini-batch  5500: 2.94008 (of which 0.63750 L1 loss)\n",
      "Loss after mini-batch  6000: 2.93733 (of which 0.63473 L1 loss)\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 2.93971 (of which 0.63712 L1 loss)\n",
      "Loss after mini-batch  1000: 2.93886 (of which 0.63628 L1 loss)\n",
      "Loss after mini-batch  1500: 2.94044 (of which 0.63786 L1 loss)\n",
      "Loss after mini-batch  2000: 2.93909 (of which 0.63651 L1 loss)\n",
      "Loss after mini-batch  2500: 2.93987 (of which 0.63728 L1 loss)\n",
      "Loss after mini-batch  3000: 2.93628 (of which 0.63369 L1 loss)\n",
      "Loss after mini-batch  3500: 2.94021 (of which 0.63763 L1 loss)\n",
      "Loss after mini-batch  4000: 2.93925 (of which 0.63667 L1 loss)\n",
      "Loss after mini-batch  4500: 2.94051 (of which 0.63792 L1 loss)\n",
      "Loss after mini-batch  5000: 2.93954 (of which 0.63696 L1 loss)\n",
      "Loss after mini-batch  5500: 2.94094 (of which 0.63835 L1 loss)\n",
      "Loss after mini-batch  6000: 2.94038 (of which 0.63779 L1 loss)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 2.94027 (of which 0.63769 L1 loss)\n",
      "Loss after mini-batch  1000: 2.93805 (of which 0.63546 L1 loss)\n",
      "Loss after mini-batch  1500: 2.93909 (of which 0.63651 L1 loss)\n",
      "Loss after mini-batch  2000: 2.93767 (of which 0.63508 L1 loss)\n",
      "Loss after mini-batch  2500: 2.94057 (of which 0.63799 L1 loss)\n",
      "Loss after mini-batch  3000: 2.93854 (of which 0.63596 L1 loss)\n",
      "Loss after mini-batch  3500: 2.94012 (of which 0.63753 L1 loss)\n",
      "Loss after mini-batch  4000: 2.93740 (of which 0.63482 L1 loss)\n",
      "Loss after mini-batch  4500: 2.94055 (of which 0.63796 L1 loss)\n",
      "Loss after mini-batch  5000: 2.93760 (of which 0.63501 L1 loss)\n",
      "Loss after mini-batch  5500: 2.93932 (of which 0.63672 L1 loss)\n",
      "Loss after mini-batch  6000: 2.93806 (of which 0.63548 L1 loss)\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 2.94168 (of which 0.63909 L1 loss)\n",
      "Loss after mini-batch  1000: 2.94057 (of which 0.63798 L1 loss)\n",
      "Loss after mini-batch  1500: 2.93999 (of which 0.63740 L1 loss)\n",
      "Loss after mini-batch  2000: 2.93795 (of which 0.63537 L1 loss)\n",
      "Loss after mini-batch  2500: 2.93965 (of which 0.63708 L1 loss)\n",
      "Loss after mini-batch  3000: 2.94087 (of which 0.63828 L1 loss)\n",
      "Loss after mini-batch  3500: 2.94016 (of which 0.63758 L1 loss)\n",
      "Loss after mini-batch  4000: 2.93791 (of which 0.63532 L1 loss)\n",
      "Loss after mini-batch  4500: 2.94201 (of which 0.63942 L1 loss)\n",
      "Loss after mini-batch  5000: 2.93726 (of which 0.63467 L1 loss)\n",
      "Loss after mini-batch  5500: 2.93892 (of which 0.63634 L1 loss)\n",
      "Loss after mini-batch  6000: 2.93942 (of which 0.63684 L1 loss)\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 2.93817 (of which 0.63559 L1 loss)\n",
      "Loss after mini-batch  1000: 2.93952 (of which 0.63695 L1 loss)\n",
      "Loss after mini-batch  1500: 2.93903 (of which 0.63645 L1 loss)\n",
      "Loss after mini-batch  2000: 2.93980 (of which 0.63721 L1 loss)\n",
      "Loss after mini-batch  2500: 2.93792 (of which 0.63534 L1 loss)\n",
      "Loss after mini-batch  3000: 2.93661 (of which 0.63402 L1 loss)\n",
      "Loss after mini-batch  3500: 2.93983 (of which 0.63723 L1 loss)\n",
      "Loss after mini-batch  4000: 2.94074 (of which 0.63816 L1 loss)\n",
      "Loss after mini-batch  4500: 2.94020 (of which 0.63761 L1 loss)\n",
      "Loss after mini-batch  5000: 2.93983 (of which 0.63726 L1 loss)\n",
      "Loss after mini-batch  5500: 2.94278 (of which 0.64020 L1 loss)\n",
      "Loss after mini-batch  6000: 2.93873 (of which 0.63615 L1 loss)\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 5): # 5 epochs at maximum\n",
    "    train_loss = 0.0\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Compute L1 loss component\n",
    "        l1_weight = 1.0\n",
    "        l1_parameters = []\n",
    "        for parameter in mlp.parameters():\n",
    "            l1_parameters.append(parameter.view(-1))\n",
    "        l1 = l1_weight * mlp.compute_l1_loss(torch.cat(l1_parameters))\n",
    "\n",
    "        # Add L1 loss component\n",
    "        loss += l1\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        minibatch_loss = loss.item()\n",
    "        train_loss += minibatch_loss\n",
    "        losses_l1.append(train_loss/(i+1))\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.5f (of which %.5f L1 loss)' %\n",
    "                (i + 1, minibatch_loss, l1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412b59a",
   "metadata": {},
   "source": [
    "### L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2644adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(28 * 28 * 1, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)\n",
    "\n",
    "    def compute_l2_loss(self, w):\n",
    "        return torch.square(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "beccda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)\n",
    "  \n",
    "mlp = MLP()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "losses_l2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d63ff1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 6.71983 (of which 4.38983 l2 loss)\n",
      "Loss after mini-batch  1000: 3.45458 (of which 1.15703 l2 loss)\n",
      "Loss after mini-batch  1500: 2.55949 (of which 0.26261 l2 loss)\n",
      "Loss after mini-batch  2000: 2.34712 (of which 0.05075 l2 loss)\n",
      "Loss after mini-batch  2500: 2.31443 (of which 0.00849 l2 loss)\n",
      "Loss after mini-batch  3000: 2.30505 (of which 0.00117 l2 loss)\n",
      "Loss after mini-batch  3500: 2.30058 (of which 0.00021 l2 loss)\n",
      "Loss after mini-batch  4000: 2.30278 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  4500: 2.30409 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  5000: 2.30292 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  5500: 2.30126 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  6000: 2.30254 (of which 0.00005 l2 loss)\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 2.30206 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  1000: 2.30201 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  1500: 2.30175 (of which 0.00010 l2 loss)\n",
      "Loss after mini-batch  2000: 2.30131 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  2500: 2.30330 (of which 0.00006 l2 loss)\n",
      "Loss after mini-batch  3000: 2.30344 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  3500: 2.30258 (of which 0.00012 l2 loss)\n",
      "Loss after mini-batch  4000: 2.30222 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  4500: 2.30383 (of which 0.00006 l2 loss)\n",
      "Loss after mini-batch  5000: 2.30374 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  5500: 2.30089 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  6000: 2.30338 (of which 0.00007 l2 loss)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 2.30207 (of which 0.00004 l2 loss)\n",
      "Loss after mini-batch  1000: 2.30201 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  1500: 2.30404 (of which 0.00010 l2 loss)\n",
      "Loss after mini-batch  2000: 2.30253 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  2500: 2.30304 (of which 0.00010 l2 loss)\n",
      "Loss after mini-batch  3000: 2.30275 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  3500: 2.30141 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  4000: 2.30257 (of which 0.00011 l2 loss)\n",
      "Loss after mini-batch  4500: 2.30337 (of which 0.00013 l2 loss)\n",
      "Loss after mini-batch  5000: 2.30284 (of which 0.00010 l2 loss)\n",
      "Loss after mini-batch  5500: 2.30187 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  6000: 2.30238 (of which 0.00006 l2 loss)\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 2.30140 (of which 0.00005 l2 loss)\n",
      "Loss after mini-batch  1000: 2.30053 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  1500: 2.30284 (of which 0.00006 l2 loss)\n",
      "Loss after mini-batch  2000: 2.30278 (of which 0.00015 l2 loss)\n",
      "Loss after mini-batch  2500: 2.30351 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  3000: 2.30186 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  3500: 2.30386 (of which 0.00013 l2 loss)\n",
      "Loss after mini-batch  4000: 2.30375 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  4500: 2.30094 (of which 0.00006 l2 loss)\n",
      "Loss after mini-batch  5000: 2.30314 (of which 0.00006 l2 loss)\n",
      "Loss after mini-batch  5500: 2.30175 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  6000: 2.30090 (of which 0.00008 l2 loss)\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 2.30229 (of which 0.00009 l2 loss)\n",
      "Loss after mini-batch  1000: 2.30243 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  1500: 2.30314 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  2000: 2.30226 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  2500: 2.30251 (of which 0.00010 l2 loss)\n",
      "Loss after mini-batch  3000: 2.30318 (of which 0.00007 l2 loss)\n",
      "Loss after mini-batch  3500: 2.30176 (of which 0.00005 l2 loss)\n",
      "Loss after mini-batch  4000: 2.30344 (of which 0.00005 l2 loss)\n",
      "Loss after mini-batch  4500: 2.30130 (of which 0.00008 l2 loss)\n",
      "Loss after mini-batch  5000: 2.30091 (of which 0.00015 l2 loss)\n",
      "Loss after mini-batch  5500: 2.30418 (of which 0.00011 l2 loss)\n",
      "Loss after mini-batch  6000: 2.30192 (of which 0.00010 l2 loss)\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 5): # 5 epochs at maximum\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      \n",
    "      # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Compute l2 loss component\n",
    "        l2_weight = 1.0\n",
    "        l2_parameters = []\n",
    "        for parameter in mlp.parameters():\n",
    "            l2_parameters.append(parameter.view(-1))\n",
    "        l2 = l2_weight * mlp.compute_l2_loss(torch.cat(l2_parameters))\n",
    "\n",
    "        # Add l2 loss component\n",
    "        loss += l2\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        minibatch_loss = loss.item()\n",
    "        train_loss += minibatch_loss\n",
    "        losses_l2.append(train_loss/(i+1))\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.5f (of which %.5f l2 loss)' %\n",
    "                (i + 1, minibatch_loss, l2))\n",
    "            current_loss = 0.0\n",
    "\n",
    "  # Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd7f5a",
   "metadata": {},
   "source": [
    "#### Простой путь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb1f76",
   "metadata": {},
   "source": [
    "В торче есть и более простой способ добавить L2-регуляризацию. <br>\n",
    "```optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4, weight_decay=1.0)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a901cf6",
   "metadata": {},
   "source": [
    "##### Реализуйте тренеровку, используя weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(???)\n",
    "losses_l2_wd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04096f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 5): # 5 epochs at maximum\n",
    "    train_loss = 0.0\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### END CODE\n",
    "\n",
    "        # Print statistics\n",
    "        minibatch_loss = loss.item()\n",
    "        train_loss += minibatch_loss\n",
    "        losses_l2_wd.append(train_loss/(i+1))\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.5f (of which %.5f l2 loss)' %\n",
    "                (i + 1, minibatch_loss, l2))\n",
    "            current_loss = 0.0\n",
    "\n",
    "  # Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f112a",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1d9d9",
   "metadata": {},
   "source": [
    "Elastic Net - взвешшеная сумма  L1 и L2 регуляризаций:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d055708",
   "metadata": {},
   "source": [
    "$$\\lambda_{L1} \\times \\sum_f{ _{i=1}^{n}} | w_i | + \\lambda_{L2} \\times \\sum_f{ _{i=1}^{n}} w_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a9445",
   "metadata": {},
   "source": [
    "И она потом добавляется к обычному лоссу:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb4634",
   "metadata": {},
   "source": [
    "$$\\text{full_loss = original_loss + } \\lambda_{L1} \\times \\sum_f{ _{i=1}^{n}} | w_i | + \\lambda_{L2} \\times \\sum_f{ _{i=1}^{n}} w_i^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a2240b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(28 * 28 * 1, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def compute_l1_loss(self, w):\n",
    "        return torch.abs(w).sum()\n",
    "\n",
    "    def compute_l2_loss(self, w):\n",
    "        return torch.square(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a37956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "  \n",
    "# Prepare CIFAR-10 dataset\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=1)\n",
    "\n",
    "# Initialize the MLP\n",
    "mlp = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "losses_elastic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "464d7a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 24.79362 (of which 19.77028 L1 loss; 2.74106 L2 loss)\n",
      "Loss after mini-batch  1000: 7.52453 (of which 4.81060 L1 loss; 0.39591 L2 loss)\n",
      "Loss after mini-batch  1500: 3.03675 (of which 0.69903 L1 loss; 0.03131 L2 loss)\n",
      "Loss after mini-batch  2000: 2.48315 (of which 0.18056 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2500: 2.48123 (of which 0.17864 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3000: 2.48011 (of which 0.17751 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3500: 2.48004 (of which 0.17745 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4000: 2.47988 (of which 0.17730 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4500: 2.47929 (of which 0.17670 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5000: 2.47955 (of which 0.17696 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5500: 2.48013 (of which 0.17754 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  6000: 2.48089 (of which 0.17830 L1 loss; 0.00001 L2 loss)\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 2.48157 (of which 0.17898 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1000: 2.48118 (of which 0.17859 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1500: 2.48204 (of which 0.17945 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2000: 2.48260 (of which 0.18001 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2500: 2.48210 (of which 0.17951 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3000: 2.48365 (of which 0.18106 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3500: 2.48438 (of which 0.18179 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4000: 2.48519 (of which 0.18259 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4500: 2.48685 (of which 0.18425 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5000: 2.48849 (of which 0.18589 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5500: 2.48777 (of which 0.18517 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  6000: 2.48826 (of which 0.18567 L1 loss; 0.00001 L2 loss)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 2.48831 (of which 0.18572 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1000: 2.48774 (of which 0.18516 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1500: 2.48812 (of which 0.18553 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2000: 2.48788 (of which 0.18529 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2500: 2.48773 (of which 0.18515 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3000: 2.48855 (of which 0.18596 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3500: 2.48858 (of which 0.18599 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4000: 2.48787 (of which 0.18528 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4500: 2.48815 (of which 0.18556 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5000: 2.48851 (of which 0.18593 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5500: 2.48780 (of which 0.18522 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  6000: 2.48869 (of which 0.18610 L1 loss; 0.00001 L2 loss)\n",
      "Starting epoch 4\n",
      "Loss after mini-batch   500: 2.48838 (of which 0.18580 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1000: 2.48777 (of which 0.18517 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1500: 2.48834 (of which 0.18575 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2000: 2.48867 (of which 0.18607 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2500: 2.48791 (of which 0.18532 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3000: 2.48808 (of which 0.18549 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3500: 2.48881 (of which 0.18622 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4000: 2.48824 (of which 0.18563 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4500: 2.48859 (of which 0.18600 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5000: 2.48807 (of which 0.18547 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5500: 2.48757 (of which 0.18496 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  6000: 2.48828 (of which 0.18567 L1 loss; 0.00001 L2 loss)\n",
      "Starting epoch 5\n",
      "Loss after mini-batch   500: 2.48850 (of which 0.18591 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1000: 2.48815 (of which 0.18556 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  1500: 2.48870 (of which 0.18612 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2000: 2.48881 (of which 0.18622 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  2500: 2.48784 (of which 0.18525 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3000: 2.48824 (of which 0.18564 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  3500: 2.48806 (of which 0.18547 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4000: 2.48741 (of which 0.18482 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  4500: 2.48861 (of which 0.18602 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5000: 2.48888 (of which 0.18629 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  5500: 2.48805 (of which 0.18546 L1 loss; 0.00001 L2 loss)\n",
      "Loss after mini-batch  6000: 2.48850 (of which 0.18590 L1 loss; 0.00001 L2 loss)\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 5): # 5 epochs at maximum\n",
    "    train_loss = 0.00\n",
    "# Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "# Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Specify L1 and L2 weights\n",
    "        l1_weight = 0.3\n",
    "        l2_weight = 0.7\n",
    "\n",
    "        # Compute L1 and L2 loss component\n",
    "        parameters = []\n",
    "        for parameter in mlp.parameters():\n",
    "            parameters.append(parameter.view(-1))\n",
    "        l1 = l1_weight * mlp.compute_l1_loss(torch.cat(parameters))\n",
    "        l2 = l2_weight * mlp.compute_l2_loss(torch.cat(parameters))\n",
    "\n",
    "        # Add L1 and L2 loss components\n",
    "        loss += l1\n",
    "        loss += l2\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        minibatch_loss = loss.item()\n",
    "        train_loss += minibatch_loss\n",
    "        losses_elastic.append(train_loss/(i+1))\n",
    "        if i % 500 == 499:\n",
    "            print('Loss after mini-batch %5d: %.5f (of which %.5f L1 loss; %0.5f L2 loss)' %\n",
    "                (i + 1, minibatch_loss, l1, l2))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ec72d62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb32aa66dd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "#losses_batchnorm = np.array(losses_batchnorm)\n",
    "#losses_no_norm = np.array(losses_no_norm)\n",
    "plt.plot(losses_l1, label='L1', alpha=0.5)\n",
    "plt.plot(losses_l2, label='L2', alpha=0.5)\n",
    "plt.plot(losses_elastic, label='Elastic', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63f54b",
   "metadata": {},
   "source": [
    "### Batch-Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba22565e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 64\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# get the training and test datasets\n",
    "train_data = MNIST(root='data', train=True,\n",
    "                            download=True, transform=transform)\n",
    "\n",
    "test_data = MNIST(root='data', train=False,\n",
    "                           download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e8325",
   "metadata": {},
   "source": [
    "Теперь в похожую полносвязную сетку добавим дропаут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "171270bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, use_batch_norm, input_size=784, hidden_dim=256, output_size=10):\n",
    "        \"\"\"\n",
    "        Creates a PyTorch net using the given parameters.\n",
    "        \n",
    "        :param use_batch_norm: bool\n",
    "            Pass True to create a network that uses batch normalization; False otherwise\n",
    "            Note: this network will not use batch normalization on layers that do not have an\n",
    "            activation function.\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__() # init super\n",
    "        \n",
    "        # Default layer sizes\n",
    "        self.input_size = input_size # (28*28 images)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size # (number of classes)\n",
    "        # Keep track of whether or not this network uses batch normalization.\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        \n",
    "        # define hidden linear layers, with optional batch norm on their outputs\n",
    "        # layers with batch_norm applied have no bias term\n",
    "        if use_batch_norm:\n",
    "            self.fc1 = nn.Linear(input_size, hidden_dim*2, bias=False)\n",
    "            self.batch_norm1 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(input_size, hidden_dim*2)\n",
    "            \n",
    "        # define *second* hidden linear layers, with optional batch norm on their outputs\n",
    "        if use_batch_norm:\n",
    "            self.fc2 = nn.Linear(hidden_dim*2, hidden_dim, bias=False)\n",
    "            self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n",
    "        else:\n",
    "            self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        # third and final, fully-connected layer\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # flatten image\n",
    "        x = x.view(-1, 28*28)\n",
    "        # all hidden layers + optional batch norm + relu activation\n",
    "        x = self.fc1(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        # second layer\n",
    "        x = self.fc2(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        # third layer, no batch norm or activation\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ddf8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=False)\n",
      "  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=False)\n",
      "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_batchnorm = NeuralNet(use_batch_norm=True)\n",
    "net_no_norm = NeuralNet(use_batch_norm=False)\n",
    "\n",
    "print(net_batchnorm)\n",
    "print()\n",
    "print(net_no_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85f366a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs=10):\n",
    "    # number of epochs to train the model\n",
    "    n_epochs = n_epochs\n",
    "    # track losses\n",
    "    losses = []\n",
    "        \n",
    "    # optimization strategy \n",
    "    # specify loss function (categorical cross-entropy)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        batch_count = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update average training loss\n",
    "            train_loss += loss.item() # add up avg batch loss\n",
    "            batch_count +=1                \n",
    "\n",
    "        # print training statistics \n",
    "        losses.append(train_loss/batch_count)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss/batch_count))\n",
    "    \n",
    "    # return all recorded batch losses\n",
    "    return losses      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ffc8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.391168\n",
      "Epoch: 2 \tTraining Loss: 0.165785\n",
      "Epoch: 3 \tTraining Loss: 0.115549\n",
      "Epoch: 4 \tTraining Loss: 0.086180\n",
      "Epoch: 5 \tTraining Loss: 0.066142\n",
      "Epoch: 6 \tTraining Loss: 0.051552\n",
      "Epoch: 7 \tTraining Loss: 0.040513\n",
      "Epoch: 8 \tTraining Loss: 0.032000\n",
      "Epoch: 9 \tTraining Loss: 0.025399\n",
      "Epoch: 10 \tTraining Loss: 0.020293\n"
     ]
    }
   ],
   "source": [
    "losses_batchnorm = train(net_batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04977f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.627025\n",
      "Epoch: 2 \tTraining Loss: 0.526522\n",
      "Epoch: 3 \tTraining Loss: 0.387258\n",
      "Epoch: 4 \tTraining Loss: 0.338334\n",
      "Epoch: 5 \tTraining Loss: 0.308756\n",
      "Epoch: 6 \tTraining Loss: 0.286501\n",
      "Epoch: 7 \tTraining Loss: 0.267729\n",
      "Epoch: 8 \tTraining Loss: 0.250841\n",
      "Epoch: 9 \tTraining Loss: 0.235325\n",
      "Epoch: 10 \tTraining Loss: 0.221022\n"
     ]
    }
   ],
   "source": [
    "losses_no_norm = train(net_no_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d567d606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb343520550>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "#losses_batchnorm = np.array(losses_batchnorm)\n",
    "#losses_no_norm = np.array(losses_no_norm)\n",
    "plt.plot(losses_batchnorm, label='Using batchnorm', alpha=0.5)\n",
    "plt.plot(losses_no_norm, label='No norm', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f626cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, train):\n",
    "    # initialize vars to monitor test loss and accuracy\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # set model to train or evaluation mode\n",
    "    # just to see the difference in behavior\n",
    "    if(train==True):\n",
    "        model.train()\n",
    "    if(train==False):\n",
    "        model.eval()\n",
    "    \n",
    "    # loss criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        batch_size = data.size(0)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss += loss.item()*batch_size\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss/len(test_loader.dataset)))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8d4e665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.083724\n",
      "\n",
      "Test Accuracy of     0: 98% (968/980)\n",
      "Test Accuracy of     1: 99% (1125/1135)\n",
      "Test Accuracy of     2: 96% (1000/1032)\n",
      "Test Accuracy of     3: 97% (982/1010)\n",
      "Test Accuracy of     4: 97% (957/982)\n",
      "Test Accuracy of     5: 97% (871/892)\n",
      "Test Accuracy of     6: 97% (934/958)\n",
      "Test Accuracy of     7: 97% (1000/1028)\n",
      "Test Accuracy of     8: 97% (948/974)\n",
      "Test Accuracy of     9: 96% (972/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9757/10000)\n"
     ]
    }
   ],
   "source": [
    "test(net_batchnorm, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4d014f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.072316\n",
      "\n",
      "Test Accuracy of     0: 98% (970/980)\n",
      "Test Accuracy of     1: 98% (1123/1135)\n",
      "Test Accuracy of     2: 97% (1006/1032)\n",
      "Test Accuracy of     3: 97% (989/1010)\n",
      "Test Accuracy of     4: 97% (954/982)\n",
      "Test Accuracy of     5: 98% (876/892)\n",
      "Test Accuracy of     6: 97% (937/958)\n",
      "Test Accuracy of     7: 96% (993/1028)\n",
      "Test Accuracy of     8: 96% (939/974)\n",
      "Test Accuracy of     9: 97% (986/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9773/10000)\n"
     ]
    }
   ],
   "source": [
    "test(net_batchnorm, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88185fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.212562\n",
      "\n",
      "Test Accuracy of     0: 98% (965/980)\n",
      "Test Accuracy of     1: 98% (1114/1135)\n",
      "Test Accuracy of     2: 90% (937/1032)\n",
      "Test Accuracy of     3: 93% (942/1010)\n",
      "Test Accuracy of     4: 93% (916/982)\n",
      "Test Accuracy of     5: 91% (816/892)\n",
      "Test Accuracy of     6: 95% (911/958)\n",
      "Test Accuracy of     7: 92% (955/1028)\n",
      "Test Accuracy of     8: 90% (885/974)\n",
      "Test Accuracy of     9: 93% (941/1009)\n",
      "\n",
      "Test Accuracy (Overall): 93% (9382/10000)\n"
     ]
    }
   ],
   "source": [
    "test(net_no_norm, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
